---
title: "MATP-4400 COVID-19 Final Notebook - Kendall Analysis and Cases per 100k by Region"
author: "Varun Nair"
date: "May 2020"
output:
  pdf_document:
    toc: yes
    toc_depth: '2'
  html_document:
    number_sections: yes
    toc: yes
    toc_depth: 2
---

```{r setup, include=FALSE}
if (!require("knitr")) {
   install.packages("knitr")
   library(knitr)
}

if (!require("ggplot2")) {
  install.packages("ggplot2")
  library(ggplot2)
}

if (!require("matlab")) {
   install.packages("matlab")
   library(matlab)
}

if (!require("ggbiplot")) {
   devtools::install_git("https://github.com/vqv/ggbiplot.git")
   library(ggbiplot)
}

if (!require("scatterplot3d")) {
  install.packages("scatterplot3d")
  library(scatterplot3d)
}

if (!require("gplots")) {
  install.packages("gplots")
  library(gplots)
}

if (!require('fields')) {
  install.packages("fields")
  library(fields)
}

if (!require('dplyr')) {
  install.packages("dplyr")
  library(dplyr)
}

if (!require("rmarkdown")) {
  install.packages("rmarkdown")
  library(rmarkdown)
}

if (!require("plotly")) {
  install.packages("plotly")
  library(plotly)
}
if (!require("Kendall")) {
  install.packages("Kendall")
  library(Kendall)
}

knitr::opts_chunk$set(echo = TRUE)

```

# Final Project: Submission Links

*This should be the first section of your final project notebook. Fill out the following according to how you submitted your notebook!*

* github repository: https://github.com/TheRensselaerIDEA/COVID-Notebooks (for reference)
* My github ID: *VarunNair22*
* github issues addressed by this work: `#17` and `#21`
* Github branch name of my submitted notebook: *VarunNair22_final*
* link to merged notebook (post these to LMS!: 
    + https://github.com/TheRensselaerIDEA/COVID-Notebooks/blob/master/MATP-4400-FINAL/COVID_FINAL_2020_VarunNair.Rmd
    + https://github.com/TheRensselaerIDEA/COVID-Notebooks/blob/master/MATP-4400-FINAL/COVID_FINAL_2020_VarunNair.html

# Overview & Problems Tackled

*Provide a top-level summary of your work and findings.*

In order to help fight the COVID-19 epidemic, data analysis is incredibly important. Any information from data analytics could be the difference between life and death for a patient. For example, certain data about different regions can give insight for how to respond in certain situations. Also, stocking adequate amounts of respirators at the correct hospital requires an understanding of where future cases are most likely going to happen. The first problem in this paper compares the correlations between different socioeconomic and health factors to see if there is any correlation between variables using Kendall Tau Analysis and Principal Component Analysis. The second problem creates a graph for the number of cases per 100k people by region in New York using ggplot.  

# Data Description

*Include data sources/locations, versions/dates, etc.* 
The first problem addresses data from the County Health rankings report, which can be found at: https://www.countyhealthrankings.org/reports. This data was cleaned and published to the MortalityMinder Github Repository here: https://github.com/TheRensselaerIDEA/MortalityMinder/tree/master/init

For the second problem, the data used is:
- New York governments data of Covid Cases per County: https://health.data.ny.gov/Health/New-York-State-Statewide-COVID-19-Testing/xdss-u53e
- Map of NY regions and counties: https://exploringupstate.com/explore-by-region/
- Population of NY counties: https://worldpopulationreview.com/us-counties/ny/

# Results

*Break out your results by each problem you attacked*

## Problem 1 

*Describe the problem you are examining.  If there is background that is necessary for this problem, then put it here. Include any references.* 

The main goal of this problem is to perform Kendall Tau analysis on county health factors for counties in NY. Kendall analysis is used to see if there is any correlation between two variables. It returns a value between -1 and 1, where 1 means the values are strongly positively correlated and -1 means the values are strongly negatively correlated. If the value is close to 0 then there's not much correlation between the two variables. also, a p value of < 0.05 is important, as otherwise the fit is more likely to be coincidental. In order to do this, data must be retrieved from the MortalityMinder repo. 

 
### Methods

*How did you address the problem? What data did you use exactly? What methods did you use?* 

There are 2 files needed to start the analysis: `chr.data.2019.reduced.rds` and `chr.data.2019.rds` from the MortalityMinder repo. `chr.data.2019.rds` has all of the data that was on the county health rankings website, while `chr.data.2019.reduced.rds` has some unimportant values filtered out. These values are socioeconomic and health data for each county in America. The code should work with `chr.data.2019.rds`. However, This has information for every US state, so the code must reduce this to just NY. Since both files have the same number of states, go through the unfiltered file and retrieve a data frame that has the NY filtered data by using a loop to iterate through both data frames. Then, perform Kendall-Tau Analysis to see how well the variables are correlated. Finally, perform PCA and plot the data to visualize the correlation.

### Results

*What were the results on this problem?*
Load the 2 separate data files into 2 data frames and clean to just have New York data.

```{r}
#read in data from files
dataFiltered <- readRDS("chr.data.2019.reduced.rds")
dataRaw <- readRDS("chr.data.2019.rds")

#store the lists of states in vector to iterate through later
statesList <- dataRaw$state_name

#These two values will record the first and last indices of what rows
#have NY data
NYCount <- 0
firstNYIndex <- 0
indexCounter <- 0

#for loop to get new york data exclusively
for (i in statesList) {
  if (all(i == "New York")) {
    if (firstNYIndex == 0) {
      #this is the first appearance of New York
      #in the loop, so record it.
      firstNYIndex <- indexCounter + 1
    }
    NYCount <- NYCount+1
  }
  indexCounter <- indexCounter+1
}
lastNYIndex <- firstNYIndex + NYCount
#This holds the filtered data for each NY county.
dataNY <- dataFiltered[firstNYIndex:lastNYIndex,]

```

In order to solve the problem, Kendall-tau and PCA were used to see how strong 2 random variables are correlated and to plot them agains each other to visualize the correlation.

Kendall Analysis can be done on individual pairs of data in order to see whether or not they correlate. Kendall Analysis was done by using the Kendall function from the Kendall package for R. For the first example, mentally unhealthy days and percent mental distress were chosen, as they have a tau value close to 1 and a low p value. 

``` {r}
#Kendall function which returns tau value (value from -1
#to 1 which tells how good correlation is) and p-value
Kendall(dataNY$mentally_unhealthy_days,dataNY$pct_frequent_mental_distress)
```

In order to show the correlation, Principle Component Analysis can be done on these two values. In order to do this, create a matrix holding the information about these two variables and scale it, then apply the prcomp function. Finally, use ggplot to plot results with the first 2 Principle coponents to show the correlation of the data for the two biggest variances. 

```{r}
#Create a scaled matrix of the input values
dataNY.matrix <- data.matrix(dataNY[,-c(1,1)])
dataNY.matrix <- scale(dataNY.matrix)

#Create a matrix holding just the 2 variables
dataPandM.matrix <- cbind(dataNY.matrix[,"mentally_unhealthy_days"], dataNY.matrix[,"pct_frequent_mental_distress"])
colnames(dataPandM.matrix) <- c("mentally_unhealthy_days", "pct_frequent_mental_distress")

#Perform Principle component Analysis
dataNY.pca<-prcomp(dataPandM.matrix,retx=TRUE)

#Plot the data
p <- ggbiplot(dataNY.pca,
            choices=c(1,2),
            alpha=.1,
            varname.adjust=1,
            obs.scale = 1,
            scale = 0)
p + ggtitle('Mentally Unhealthy Days and Frequent Mental Distress Projected on PC1 and PC2') + xlim(-5,5) + ylim(-3,3)
```

As seen above, the data has a strong positive trend, which shows that having high mentally unhealthy days leads to a high percentage of mentall distress amoung regions. 

Another Kendall Analysis can be performed between physically and mentally unstable days.

```{r}
Kendall(dataNY$mentally_unhealthy_days,dataNY$physically_unhealthy_days)
```

While the p value is low, the tau value is not very close to 1, so it is likely that the data is only slightly correlated. This can be seen by repeating the analysis done for the previous pair of data.

```{r}
#Create a scaled matrix of the input values
dataNY.matrix <- data.matrix(dataNY[,-c(1,1)])
dataNY.matrix <- scale(dataNY.matrix)

#Create a matrix holding just the 2 variables
dataPandM.matrix <- cbind(dataNY.matrix[,"mentally_unhealthy_days"], dataNY.matrix[,"physically_unhealthy_days"])
colnames(dataPandM.matrix) <- c("mentally_unhealthy_days", "physically_unhealthy_days")

#Perform Principle component Analysis
dataNY.pca<-prcomp(dataPandM.matrix,retx=TRUE)

#Plot the data
p <- ggbiplot(dataNY.pca,
            choices=c(1,2),
            alpha=.1,
            varname.adjust=1,
            obs.scale = 1,
            scale = 0)
p + ggtitle('Mentally and Physically Unhealthy Days Projected on PC1 and PC2') + xlim(-5,5) + ylim(-3,3)
```


### Discussion

*Interpret results.  What were your findings?  What do they say about COVID-19?   What are the strengths and limitations of these results? Is there support for your findings from other sources? Include references as appropriate.*

As seen above, some data is more correlated than others. This data can be used to treat patients who have corona. For example, making sure people have good physical and mental health is important in order to overcome the virus. The slight trend shows that both of these are somewhat correlated, so healthcare workers can make sure people are in the best health. This is corroborated by many academic journals, such as this one: https://www.sciencedirect.com/science/article/pii/S0277953617306639

## Problem 2

The main goal of this problem is to create a visualization that shows the cases per 100k people by region in New York State. The purpose of this is to show weather or not the reopening of regions would be viable. The current model for this in COVID minder is by county, so the data is a bit cluttered. By looking regionally, a more broad understanding can be made to show how COVID is impacting all regions, and appropriate measures can be taken in terms of social distancing.

### Methods

The first dataset used for this problem contains the total number of cases in each New York county and the second data set holds the population values of each NY county. See `Data Description` for source. For this problem, the code must first create groupings for each region and what counties they include. Since no list was found online, This was done manually. Next, the number of cases per 100k people must be calculated. This was done by adding the total number of cases from each county in the region and dividing that by the total population of the region, and finally multiplying this number by 100,000. This was done for every date and region in the data set. Then, a data frame needed to be created that held all of this data as well as the names of regions for graphing purposes. Finally, the data frame was plotted to show the progression of Covid Cases in regions of New York.

### Results
First, read in the population and Covid data into 2 seperate data frames. Also, manually define the regions and their counties
```{r}
#read in population and Covid data
CovidCases.df <- read.csv("New_York_State_Statewide_COVID-19_Testing.csv")
Population.df <- read.csv("County_Population.csv")

NYC <- c("Bronx", "Queens", "Kings", "Richmond", "New York")
LI <- c("Nassau", "Suffolk")
Catskills <- c("Delaware", "Sullivan", "Ulster", "Greene")
HVR <- c("Orange", "Rockland", "Westchester", "Putnam", "Dutchess", "Columbia")
Capital <- c("Albany", "Rensselaer", "Schenectady", "Saratoga")
Aiderondack <- c("Lewis", "Fulton", "Herkimer", "Hamilton", "Warren", "Washington", "Essex", "Franklin", "Clinton")
Thousand <- c("Jefferson", "Oswego", "St. Lawrence")
Finger <- c("Monroe", "Livingston", "Steuben", "Ontario", "Wayne", "Yates", "Seneca", "Schuyler", "Chemung", "Tioga", "Tompkins", "Cayuga", "Cortland", "Onondaga")
Niagara <- c("Niagara", "Erie", "Orleans", "Genesee", "Wyoming")
Chautaqua <- c("Allegany", "Cattaraugus", "Chautauqua")
Central <- c("Oneida", "Madison", "Chenango", "Broome", "Otsego", "Schoharie", "Montgomery")

#below was done to check that all county values are correct.
#useful incase doing test for another state manually and
#want to check correctness. If all counties print, then successful.

#b <- 0

#for (i in Central) {
#  temp <- paste(i, "County")
#  for (j in Population.df$CTYNAME) {
#    if (all(temp == j)) {
#      b <- b+1
#      print(i)
#      break
#    }
#  }
#}

#b
#str(Central)
```

Next, a function to calculate the covid cases per 100k people by region is created. Goes through all counties in region, sums up the total population and case number for the region, and calculates case/100k people. 

```{r}
per100k <- function(region, dateInp) {
  #This function calculates the positive rate per 100k people in each
  #New York Region. 
  #Inputs: vector region with county strings as values, int dateInp as
  #date to check.
  totalCases <- 0
  totalPopulation <- 0
  for (county in region) {
    #loop through evey county in region
    rowIter <- 1
    currentDate <- CovidCases.df[rowIter, "Test.Date"]
    while (currentDate != dateInp) {
      #get index of correct date
      rowIter <- rowIter + nrow(Population.df)
      currentDate <- CovidCases.df[rowIter, "Test.Date"]
    }
    currentCounty <- CovidCases.df[rowIter, "County"]
    while (all(currentCounty != county)) {
      #get index of correct date and county
      rowIter <- rowIter+1
      currentCounty <- CovidCases.df[rowIter, "County"]
    }
    totalCases <- totalCases + CovidCases.df[rowIter, "Cumulative.Number.of.Positives"]
    popIter <- 1
    popCounty <- paste(county, "County")
    currentCounty <- Population.df[popIter, "CTYNAME"]
    while (all(currentCounty != popCounty)) {
      #get index of correct county in population data
      popIter <- popIter +1
      currentCounty <- Population.df[popIter, "CTYNAME"]
    }
    totalPopulation <- totalPopulation + Population.df[popIter, "Pop"]
  }
  scaledPop <- totalPopulation/100000
  casesScaled <- totalCases/scaledPop
  return(casesScaled)
}
```

The block below calculates the values for each region at every date and stores it in a vector

```{r}
iterationCount <- nrow(CovidCases.df)/62
#initialize vectors to hold the cases/100k for each region
NYC100k <- c()
LI100k <- c()
Catskills100k <- c()
HVR100k <- c()
Capital100k <- c()
Aiderondack100k <- c()
Thousand100k <- c()
Finger100k <- c()
Niagara100k <- c()
Chautaqua100k <- c()
Central100k <- c()


i <- nrow(CovidCases.df)
#counter will store the total number of days in the graph.
counter <- 0
while (i > 0) {
  #loop backwards through all dates to get the cases/100k
  #for each region. i - 62 at each iteration because that is 
  #how many counties there is and hence the distance to get back
  #to the day before.
  NYC100k <- c(NYC100k, per100k(NYC, CovidCases.df[i, "Test.Date"]))
  LI100k <- c(LI100k, per100k(LI, CovidCases.df[i, "Test.Date"]))
  Catskills100k <- c(Catskills100k, per100k(Catskills, CovidCases.df[i, "Test.Date"]))
  HVR100k <- c(HVR100k, per100k(HVR, CovidCases.df[i, "Test.Date"]))
  Capital100k <- c(Capital100k, per100k(Capital, CovidCases.df[i, "Test.Date"]))
  Aiderondack100k <- c(Aiderondack100k, per100k(Aiderondack, CovidCases.df[i, "Test.Date"]))
  Thousand100k <- c(Thousand100k, per100k(Thousand, CovidCases.df[i, "Test.Date"]))
  Finger100k <- c(Finger100k, per100k(Finger, CovidCases.df[i, "Test.Date"]))
  Niagara100k <- c(Niagara100k, per100k(Niagara, CovidCases.df[i, "Test.Date"]))
  Chautaqua100k <- c(Chautaqua100k, per100k(Chautaqua, CovidCases.df[i, "Test.Date"]))
  Central100k <- c(Central100k, per100k(Central, CovidCases.df[i, "Test.Date"]))
  i <- i - 62
  counter <- counter + 1
}
```

The Code block below defines the data frame that needs to be graphed, and uses ggplot to graph the data.

```{r}
#Store all values into a vector
allVals <- c(Aiderondack100k, Capital100k, Catskills100k, Central100k, Chautaqua100k, Finger100k, HVR100k, LI100k, NYC100k, Niagara100k, Thousand100k)

#Stores list of all dates from beginning to present in firstDate
temp <- counter -1
firstDate <- as.Date("2020-03-02") + 0:temp

#Region Names for labeling graph
regions <- c("Aiderondack Region", "Capital Region", "Catskills Region", "Central NY Region", "Chautaqua-Alleghany Region", "Finger Lakes Region", "Hudson Valley Region", "Long Island", "New York City", "Niagara Frontier Region", "Thousand Island")

#Data frame used in ggplot
graph.df <- data.frame(date = firstDate, val = allVals, variable=rep(regions, each=counter))

##ggplot: ggplot used to plot data, geom_line to ensure it is
#line graph, scale_y_continuous to make scale of y axis correct
#(was taken from file from covid minder),
#ylab, xlab, and ggtitle to clarify the data on display.
#New York shortened to NY to fit in space
ggplot(data = graph.df, aes(date,val)) + 
  geom_line(aes(colour=variable)) + 
  scale_y_continuous(
    trans = "log10",
    breaks = c(100,500,1000,5000)
  ) + 
  ylab("Cases per 100K Population") + 
  xlab("Bi-weekly Date")+
  ggtitle("NY State COVID-19 Cases per 100K Population by Region (Mar-May 2020)")
```

### Discussion

The graph above shows the severity of Covid in certain areas, but also shows how it is not as big a factor in others. For example, the Allegheny region has much less cases compared to the Hudson Valley region, so this area could be opened up soon. However, while a region like the Capital region might not have a lot of cases, it is bordered with the Hudson Valley Region, so opening it early would not be a very good idea due to proximity to such a high density area. This information can be monitored to determine when Social distancing can end, so it is very important.

# Summary and COVIDMINDER Recommendations

* Overall, what insights did you find  about the  COVID-19 epidemic in your analysis?
- Many health factors should be monitored, and finding relations between 2 factors can help a lot when treating Covid patients. Also, the trend for cases seems to be flattening, meaning if social distancing is maintained for just a bit longer, hopefully there will be less cases soon. The disparity between different regions in NYC in terms of Covid is shown above.

* What recommendations do you have for COVIDMINDER for  Data utilization, Analytics, Visualizations, User interface design, etc.
- I think that CovidMinder is a great idea and has a lot of great information! I would just suggest adding a lot more graphs to show a lot of visualization. The more data there is the better!
- I think the answer to my first problem should not be included. It is more useful as something other analysts can use to determine health patterns compared to something that would be used by the public. I believe that the second problem is deployable though. 
- For the first problem, If a less complex analysis than PCA was used, then I think it would be appropriate for CovidMinder. For the second problem, I think that adding some interactivity elements would help it be a better graph. For example, showing specific date data by hovering over a line on the graph would be great.


*Think of yourself as a consultant reporting back on a particular aspect of the analysis and application design!*

# References

- https://www.countyhealthrankings.org/reports
- https://github.com/TheRensselaerIDEA/MortalityMinder/tree/master/init
- https://health.data.ny.gov/Health/New-York-State-Statewide-COVID-19-Testing/xdss-u53e
- https://exploringupstate.com/explore-by-region/
- https://worldpopulationreview.com/us-counties/ny/
- https://www.sciencedirect.com/science/article/pii/S0277953617306639


